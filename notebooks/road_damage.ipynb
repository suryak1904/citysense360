{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0575a3b",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "\n",
    "This notebook was trained on the RDD2022 dataset using Kaggle.\n",
    "Due to the large dataset size, training was performed in the Kaggle environment.\n",
    "\n",
    "For local execution, update the `DATASET_ROOT` path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478f2d3e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:22.502694Z",
     "iopub.status.busy": "2025-09-09T08:24:22.502359Z",
     "iopub.status.idle": "2025-09-09T08:24:32.677741Z",
     "shell.execute_reply": "2025-09-09T08:24:32.677102Z"
    },
    "papermill": {
     "duration": 10.180607,
     "end_time": "2025-09-09T08:24:32.679177",
     "exception": false,
     "start_time": "2025-09-09T08:24:22.498570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ea645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:32.683844Z",
     "iopub.status.busy": "2025-09-09T08:24:32.683553Z",
     "iopub.status.idle": "2025-09-09T08:24:32.691622Z",
     "shell.execute_reply": "2025-09-09T08:24:32.691110Z"
    },
    "papermill": {
     "duration": 0.011354,
     "end_time": "2025-09-09T08:24:32.692693",
     "exception": false,
     "start_time": "2025-09-09T08:24:32.681339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RDD2022Dataset(Dataset):\n",
    "    def __init__(self, root, split=\"train\", transforms=None):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.img_dir = os.path.join(root, split, \"images\")\n",
    "        self.label_dir = os.path.join(root, split, \"labels\")\n",
    "\n",
    "        self.imgs = sorted(os.listdir(self.img_dir))\n",
    "        self.labels = sorted(os.listdir(self.label_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = img.size\n",
    "        label_path = os.path.join(self.label_dir, self.labels[idx])\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path) as f:\n",
    "                for line in f.readlines():\n",
    "                    cls, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                    cls = int(cls) + 1  \n",
    "                    xmin = (x_center - w / 2) * img_width\n",
    "                    xmax = (x_center + w / 2) * img_width\n",
    "                    ymin = (y_center - h / 2) * img_height\n",
    "                    ymax = (y_center + h / 2) * img_height\n",
    "                    if xmax > xmin and ymax > ymin:\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "                        labels.append(cls)\n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073a43b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:32.696731Z",
     "iopub.status.busy": "2025-09-09T08:24:32.696206Z",
     "iopub.status.idle": "2025-09-09T08:24:32.701764Z",
     "shell.execute_reply": "2025-09-09T08:24:32.701258Z"
    },
    "papermill": {
     "duration": 0.008603,
     "end_time": "2025-09-09T08:24:32.702793",
     "exception": false,
     "start_time": "2025-09-09T08:24:32.694190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComposeTransforms:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, image, target):\n",
    "        return F.to_tensor(image), target\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if np.random.rand() < self.p:\n",
    "            image = F.hflip(image)\n",
    "            _, h, w = image.shape\n",
    "            boxes = target[\"boxes\"]\n",
    "            boxes[:, [0, 2]] = w - boxes[:, [2, 0]]\n",
    "            target[\"boxes\"] = boxes\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = [ToTensor()]\n",
    "    if train:\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "    return ComposeTransforms(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12b5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:32.706365Z",
     "iopub.status.busy": "2025-09-09T08:24:32.706192Z",
     "iopub.status.idle": "2025-09-09T08:24:32.709565Z",
     "shell.execute_reply": "2025-09-09T08:24:32.709051Z"
    },
    "papermill": {
     "duration": 0.006292,
     "end_time": "2025-09-09T08:24:32.710544",
     "exception": false,
     "start_time": "2025-09-09T08:24:32.704252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c4ec2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:32.714101Z",
     "iopub.status.busy": "2025-09-09T08:24:32.713905Z",
     "iopub.status.idle": "2025-09-09T08:24:32.718680Z",
     "shell.execute_reply": "2025-09-09T08:24:32.718157Z"
    },
    "papermill": {
     "duration": 0.007741,
     "end_time": "2025-09-09T08:24:32.719728",
     "exception": false,
     "start_time": "2025-09-09T08:24:32.711987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50):\n",
    "    model.train()\n",
    "    for i, (images, targets) in enumerate(data_loader):\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(f\"Epoch [{epoch}] Iter [{i}/{len(data_loader)}] Loss: {losses.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a5672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:24:32.723607Z",
     "iopub.status.busy": "2025-09-09T08:24:32.723394Z",
     "iopub.status.idle": "2025-09-09T13:57:25.277736Z",
     "shell.execute_reply": "2025-09-09T13:57:25.276865Z"
    },
    "papermill": {
     "duration": 19972.557977,
     "end_time": "2025-09-09T13:57:25.279303",
     "exception": false,
     "start_time": "2025-09-09T08:24:32.721326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|██████████| 160M/160M [00:00<00:00, 210MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] Iter [0/6718] Loss: 4.5357\n",
      "Epoch [0] Iter [100/6718] Loss: 0.1669\n",
      "Epoch [0] Iter [200/6718] Loss: 0.1839\n",
      "Epoch [0] Iter [300/6718] Loss: 0.3806\n",
      "Epoch [0] Iter [400/6718] Loss: 0.5278\n",
      "Epoch [0] Iter [500/6718] Loss: 0.1133\n",
      "Epoch [0] Iter [600/6718] Loss: 0.1344\n",
      "Epoch [0] Iter [700/6718] Loss: 0.4814\n",
      "Epoch [0] Iter [800/6718] Loss: 0.1362\n",
      "Epoch [0] Iter [900/6718] Loss: 0.2128\n",
      "Epoch [0] Iter [1000/6718] Loss: 0.1936\n",
      "Epoch [0] Iter [1100/6718] Loss: 0.5642\n",
      "Epoch [0] Iter [1200/6718] Loss: 0.3331\n",
      "Epoch [0] Iter [1300/6718] Loss: 0.8158\n",
      "Epoch [0] Iter [1400/6718] Loss: 0.3687\n",
      "Epoch [0] Iter [1500/6718] Loss: 0.3294\n",
      "Epoch [0] Iter [1600/6718] Loss: 0.4338\n",
      "Epoch [0] Iter [1700/6718] Loss: 0.3871\n",
      "Epoch [0] Iter [1800/6718] Loss: 0.2480\n",
      "Epoch [0] Iter [1900/6718] Loss: 0.1299\n",
      "Epoch [0] Iter [2000/6718] Loss: 0.2740\n",
      "Epoch [0] Iter [2100/6718] Loss: 0.1164\n",
      "Epoch [0] Iter [2200/6718] Loss: 0.3820\n",
      "Epoch [0] Iter [2300/6718] Loss: 0.7547\n",
      "Epoch [0] Iter [2400/6718] Loss: 0.5167\n",
      "Epoch [0] Iter [2500/6718] Loss: 0.4044\n",
      "Epoch [0] Iter [2600/6718] Loss: 0.2441\n",
      "Epoch [0] Iter [2700/6718] Loss: 0.3209\n",
      "Epoch [0] Iter [2800/6718] Loss: 0.5025\n",
      "Epoch [0] Iter [2900/6718] Loss: 0.1835\n",
      "Epoch [0] Iter [3000/6718] Loss: 0.6405\n",
      "Epoch [0] Iter [3100/6718] Loss: 0.0613\n",
      "Epoch [0] Iter [3200/6718] Loss: 0.2691\n",
      "Epoch [0] Iter [3300/6718] Loss: 0.2113\n",
      "Epoch [0] Iter [3400/6718] Loss: 0.3302\n",
      "Epoch [0] Iter [3500/6718] Loss: 0.1113\n",
      "Epoch [0] Iter [3600/6718] Loss: 0.3565\n",
      "Epoch [0] Iter [3700/6718] Loss: 0.0408\n",
      "Epoch [0] Iter [3800/6718] Loss: 0.1921\n",
      "Epoch [0] Iter [3900/6718] Loss: 0.3381\n",
      "Epoch [0] Iter [4000/6718] Loss: 0.0494\n",
      "Epoch [0] Iter [4100/6718] Loss: 0.2298\n",
      "Epoch [0] Iter [4200/6718] Loss: 0.0629\n",
      "Epoch [0] Iter [4300/6718] Loss: 0.2229\n",
      "Epoch [0] Iter [4400/6718] Loss: 0.2974\n",
      "Epoch [0] Iter [4500/6718] Loss: 0.1574\n",
      "Epoch [0] Iter [4600/6718] Loss: 0.1297\n",
      "Epoch [0] Iter [4700/6718] Loss: 0.1829\n",
      "Epoch [0] Iter [4800/6718] Loss: 0.1634\n",
      "Epoch [0] Iter [4900/6718] Loss: 0.4805\n",
      "Epoch [0] Iter [5000/6718] Loss: 0.3484\n",
      "Epoch [0] Iter [5100/6718] Loss: 0.0924\n",
      "Epoch [0] Iter [5200/6718] Loss: 0.2563\n",
      "Epoch [0] Iter [5300/6718] Loss: 0.2310\n",
      "Epoch [0] Iter [5400/6718] Loss: 0.2281\n",
      "Epoch [0] Iter [5500/6718] Loss: 0.5812\n",
      "Epoch [0] Iter [5600/6718] Loss: 0.1543\n",
      "Epoch [0] Iter [5700/6718] Loss: 0.4698\n",
      "Epoch [0] Iter [5800/6718] Loss: 0.0524\n",
      "Epoch [0] Iter [5900/6718] Loss: 0.2440\n",
      "Epoch [0] Iter [6000/6718] Loss: 0.6147\n",
      "Epoch [0] Iter [6100/6718] Loss: 0.4186\n",
      "Epoch [0] Iter [6200/6718] Loss: 0.2947\n",
      "Epoch [0] Iter [6300/6718] Loss: 0.1699\n",
      "Epoch [0] Iter [6400/6718] Loss: 0.4390\n",
      "Epoch [0] Iter [6500/6718] Loss: 0.1430\n",
      "Epoch [0] Iter [6600/6718] Loss: 0.5496\n",
      "Epoch [0] Iter [6700/6718] Loss: 0.4356\n",
      "Epoch [1] Iter [0/6718] Loss: 0.0755\n",
      "Epoch [1] Iter [100/6718] Loss: 0.2210\n",
      "Epoch [1] Iter [200/6718] Loss: 0.2693\n",
      "Epoch [1] Iter [300/6718] Loss: 0.4873\n",
      "Epoch [1] Iter [400/6718] Loss: 0.2022\n",
      "Epoch [1] Iter [500/6718] Loss: 0.4270\n",
      "Epoch [1] Iter [600/6718] Loss: 0.2377\n",
      "Epoch [1] Iter [700/6718] Loss: 0.1909\n",
      "Epoch [1] Iter [800/6718] Loss: 0.1702\n",
      "Epoch [1] Iter [900/6718] Loss: 0.0935\n",
      "Epoch [1] Iter [1000/6718] Loss: 0.2454\n",
      "Epoch [1] Iter [1100/6718] Loss: 0.2947\n",
      "Epoch [1] Iter [1200/6718] Loss: 0.1187\n",
      "Epoch [1] Iter [1300/6718] Loss: 0.6691\n",
      "Epoch [1] Iter [1400/6718] Loss: 0.1999\n",
      "Epoch [1] Iter [1500/6718] Loss: 0.1077\n",
      "Epoch [1] Iter [1600/6718] Loss: 0.1805\n",
      "Epoch [1] Iter [1700/6718] Loss: 0.4776\n",
      "Epoch [1] Iter [1800/6718] Loss: 0.5432\n",
      "Epoch [1] Iter [1900/6718] Loss: 0.2231\n",
      "Epoch [1] Iter [2000/6718] Loss: 0.2570\n",
      "Epoch [1] Iter [2100/6718] Loss: 0.0394\n",
      "Epoch [1] Iter [2200/6718] Loss: 0.2594\n",
      "Epoch [1] Iter [2300/6718] Loss: 0.1624\n",
      "Epoch [1] Iter [2400/6718] Loss: 0.3184\n",
      "Epoch [1] Iter [2500/6718] Loss: 0.3745\n",
      "Epoch [1] Iter [2600/6718] Loss: 0.3468\n",
      "Epoch [1] Iter [2700/6718] Loss: 0.6518\n",
      "Epoch [1] Iter [2800/6718] Loss: 0.1475\n",
      "Epoch [1] Iter [2900/6718] Loss: 0.3448\n",
      "Epoch [1] Iter [3000/6718] Loss: 0.1071\n",
      "Epoch [1] Iter [3100/6718] Loss: 0.3672\n",
      "Epoch [1] Iter [3200/6718] Loss: 0.1076\n",
      "Epoch [1] Iter [3300/6718] Loss: 0.4497\n",
      "Epoch [1] Iter [3400/6718] Loss: 0.2924\n",
      "Epoch [1] Iter [3500/6718] Loss: 0.4593\n",
      "Epoch [1] Iter [3600/6718] Loss: 0.3421\n",
      "Epoch [1] Iter [3700/6718] Loss: 0.1129\n",
      "Epoch [1] Iter [3800/6718] Loss: 0.2912\n",
      "Epoch [1] Iter [3900/6718] Loss: 0.3868\n",
      "Epoch [1] Iter [4000/6718] Loss: 0.2332\n",
      "Epoch [1] Iter [4100/6718] Loss: 0.1065\n",
      "Epoch [1] Iter [4200/6718] Loss: 0.4774\n",
      "Epoch [1] Iter [4300/6718] Loss: 0.3270\n",
      "Epoch [1] Iter [4400/6718] Loss: 0.1004\n",
      "Epoch [1] Iter [4500/6718] Loss: 0.3261\n",
      "Epoch [1] Iter [4600/6718] Loss: 0.1420\n",
      "Epoch [1] Iter [4700/6718] Loss: 0.1746\n",
      "Epoch [1] Iter [4800/6718] Loss: 0.0431\n",
      "Epoch [1] Iter [4900/6718] Loss: 0.4288\n",
      "Epoch [1] Iter [5000/6718] Loss: 0.3028\n",
      "Epoch [1] Iter [5100/6718] Loss: 0.1720\n",
      "Epoch [1] Iter [5200/6718] Loss: 0.0970\n",
      "Epoch [1] Iter [5300/6718] Loss: 0.1178\n",
      "Epoch [1] Iter [5400/6718] Loss: 0.2869\n",
      "Epoch [1] Iter [5500/6718] Loss: 0.2613\n",
      "Epoch [1] Iter [5600/6718] Loss: 0.2686\n",
      "Epoch [1] Iter [5700/6718] Loss: 0.0411\n",
      "Epoch [1] Iter [5800/6718] Loss: 0.1824\n",
      "Epoch [1] Iter [5900/6718] Loss: 0.3459\n",
      "Epoch [1] Iter [6000/6718] Loss: 0.3308\n",
      "Epoch [1] Iter [6100/6718] Loss: 0.2592\n",
      "Epoch [1] Iter [6200/6718] Loss: 0.0670\n",
      "Epoch [1] Iter [6300/6718] Loss: 0.2987\n",
      "Epoch [1] Iter [6400/6718] Loss: 0.3257\n",
      "Epoch [1] Iter [6500/6718] Loss: 0.3010\n",
      "Epoch [1] Iter [6600/6718] Loss: 0.0742\n",
      "Epoch [1] Iter [6700/6718] Loss: 0.2948\n",
      "Epoch [2] Iter [0/6718] Loss: 0.0557\n",
      "Epoch [2] Iter [100/6718] Loss: 0.2892\n",
      "Epoch [2] Iter [200/6718] Loss: 0.2826\n",
      "Epoch [2] Iter [300/6718] Loss: 0.0799\n",
      "Epoch [2] Iter [400/6718] Loss: 0.0847\n",
      "Epoch [2] Iter [500/6718] Loss: 0.2258\n",
      "Epoch [2] Iter [600/6718] Loss: 0.0100\n",
      "Epoch [2] Iter [700/6718] Loss: 0.2613\n",
      "Epoch [2] Iter [800/6718] Loss: 0.2305\n",
      "Epoch [2] Iter [900/6718] Loss: 0.2232\n",
      "Epoch [2] Iter [1000/6718] Loss: 0.2570\n",
      "Epoch [2] Iter [1100/6718] Loss: 0.0975\n",
      "Epoch [2] Iter [1200/6718] Loss: 0.1112\n",
      "Epoch [2] Iter [1300/6718] Loss: 0.0787\n",
      "Epoch [2] Iter [1400/6718] Loss: 0.1258\n",
      "Epoch [2] Iter [1500/6718] Loss: 0.0753\n",
      "Epoch [2] Iter [1600/6718] Loss: 0.1820\n",
      "Epoch [2] Iter [1700/6718] Loss: 0.2613\n",
      "Epoch [2] Iter [1800/6718] Loss: 0.0767\n",
      "Epoch [2] Iter [1900/6718] Loss: 0.1574\n",
      "Epoch [2] Iter [2000/6718] Loss: 0.2603\n",
      "Epoch [2] Iter [2100/6718] Loss: 0.1338\n",
      "Epoch [2] Iter [2200/6718] Loss: 0.0409\n",
      "Epoch [2] Iter [2300/6718] Loss: 0.3153\n",
      "Epoch [2] Iter [2400/6718] Loss: 0.1772\n",
      "Epoch [2] Iter [2500/6718] Loss: 0.0805\n",
      "Epoch [2] Iter [2600/6718] Loss: 0.1044\n",
      "Epoch [2] Iter [2700/6718] Loss: 0.1839\n",
      "Epoch [2] Iter [2800/6718] Loss: 0.1709\n",
      "Epoch [2] Iter [2900/6718] Loss: 0.2243\n",
      "Epoch [2] Iter [3000/6718] Loss: 0.2990\n",
      "Epoch [2] Iter [3100/6718] Loss: 0.1835\n",
      "Epoch [2] Iter [3200/6718] Loss: 0.3497\n",
      "Epoch [2] Iter [3300/6718] Loss: 0.3115\n",
      "Epoch [2] Iter [3400/6718] Loss: 0.1148\n",
      "Epoch [2] Iter [3500/6718] Loss: 0.3433\n",
      "Epoch [2] Iter [3600/6718] Loss: 0.5018\n",
      "Epoch [2] Iter [3700/6718] Loss: 0.1624\n",
      "Epoch [2] Iter [3800/6718] Loss: 0.3757\n",
      "Epoch [2] Iter [3900/6718] Loss: 0.2720\n",
      "Epoch [2] Iter [4000/6718] Loss: 0.1900\n",
      "Epoch [2] Iter [4100/6718] Loss: 0.6019\n",
      "Epoch [2] Iter [4200/6718] Loss: 0.3388\n",
      "Epoch [2] Iter [4300/6718] Loss: 0.3188\n",
      "Epoch [2] Iter [4400/6718] Loss: 0.1410\n",
      "Epoch [2] Iter [4500/6718] Loss: 0.3630\n",
      "Epoch [2] Iter [4600/6718] Loss: 0.1246\n",
      "Epoch [2] Iter [4700/6718] Loss: 0.2287\n",
      "Epoch [2] Iter [4800/6718] Loss: 0.2103\n",
      "Epoch [2] Iter [4900/6718] Loss: 0.1365\n",
      "Epoch [2] Iter [5000/6718] Loss: 0.1807\n",
      "Epoch [2] Iter [5100/6718] Loss: 0.3116\n",
      "Epoch [2] Iter [5200/6718] Loss: 0.1473\n",
      "Epoch [2] Iter [5300/6718] Loss: 0.5980\n",
      "Epoch [2] Iter [5400/6718] Loss: 0.1511\n",
      "Epoch [2] Iter [5500/6718] Loss: 0.4109\n",
      "Epoch [2] Iter [5600/6718] Loss: 0.2344\n",
      "Epoch [2] Iter [5700/6718] Loss: 0.1786\n",
      "Epoch [2] Iter [5800/6718] Loss: 0.1571\n",
      "Epoch [2] Iter [5900/6718] Loss: 0.1463\n",
      "Epoch [2] Iter [6000/6718] Loss: 0.2725\n",
      "Epoch [2] Iter [6100/6718] Loss: 0.3540\n",
      "Epoch [2] Iter [6200/6718] Loss: 0.3075\n",
      "Epoch [2] Iter [6300/6718] Loss: 0.1968\n",
      "Epoch [2] Iter [6400/6718] Loss: 0.2757\n",
      "Epoch [2] Iter [6500/6718] Loss: 0.2073\n",
      "Epoch [2] Iter [6600/6718] Loss: 0.1295\n",
      "Epoch [2] Iter [6700/6718] Loss: 0.3029\n",
      "Epoch [3] Iter [0/6718] Loss: 0.1137\n",
      "Epoch [3] Iter [100/6718] Loss: 0.1619\n",
      "Epoch [3] Iter [200/6718] Loss: 0.3634\n",
      "Epoch [3] Iter [300/6718] Loss: 0.1451\n",
      "Epoch [3] Iter [400/6718] Loss: 0.1469\n",
      "Epoch [3] Iter [500/6718] Loss: 0.1784\n",
      "Epoch [3] Iter [600/6718] Loss: 0.0771\n",
      "Epoch [3] Iter [700/6718] Loss: 0.1720\n",
      "Epoch [3] Iter [800/6718] Loss: 0.1716\n",
      "Epoch [3] Iter [900/6718] Loss: 0.1418\n",
      "Epoch [3] Iter [1000/6718] Loss: 0.0481\n",
      "Epoch [3] Iter [1100/6718] Loss: 0.2252\n",
      "Epoch [3] Iter [1200/6718] Loss: 0.1859\n",
      "Epoch [3] Iter [1300/6718] Loss: 0.2684\n",
      "Epoch [3] Iter [1400/6718] Loss: 0.1130\n",
      "Epoch [3] Iter [1500/6718] Loss: 0.1307\n",
      "Epoch [3] Iter [1600/6718] Loss: 0.2234\n",
      "Epoch [3] Iter [1700/6718] Loss: 0.0988\n",
      "Epoch [3] Iter [1800/6718] Loss: 0.1618\n",
      "Epoch [3] Iter [1900/6718] Loss: 0.1799\n",
      "Epoch [3] Iter [2000/6718] Loss: 0.0959\n",
      "Epoch [3] Iter [2100/6718] Loss: 0.1314\n",
      "Epoch [3] Iter [2200/6718] Loss: 0.0588\n",
      "Epoch [3] Iter [2300/6718] Loss: 0.1060\n",
      "Epoch [3] Iter [2400/6718] Loss: 0.1585\n",
      "Epoch [3] Iter [2500/6718] Loss: 0.3694\n",
      "Epoch [3] Iter [2600/6718] Loss: 0.1423\n",
      "Epoch [3] Iter [2700/6718] Loss: 0.1259\n",
      "Epoch [3] Iter [2800/6718] Loss: 0.3440\n",
      "Epoch [3] Iter [2900/6718] Loss: 0.0602\n",
      "Epoch [3] Iter [3000/6718] Loss: 0.2504\n",
      "Epoch [3] Iter [3100/6718] Loss: 0.0440\n",
      "Epoch [3] Iter [3200/6718] Loss: 0.2563\n",
      "Epoch [3] Iter [3300/6718] Loss: 0.4018\n",
      "Epoch [3] Iter [3400/6718] Loss: 0.0586\n",
      "Epoch [3] Iter [3500/6718] Loss: 0.2401\n",
      "Epoch [3] Iter [3600/6718] Loss: 0.1813\n",
      "Epoch [3] Iter [3700/6718] Loss: 0.2454\n",
      "Epoch [3] Iter [3800/6718] Loss: 0.4800\n",
      "Epoch [3] Iter [3900/6718] Loss: 0.2745\n",
      "Epoch [3] Iter [4000/6718] Loss: 0.2732\n",
      "Epoch [3] Iter [4100/6718] Loss: 0.2901\n",
      "Epoch [3] Iter [4200/6718] Loss: 0.1780\n",
      "Epoch [3] Iter [4300/6718] Loss: 0.0720\n",
      "Epoch [3] Iter [4400/6718] Loss: 0.2642\n",
      "Epoch [3] Iter [4500/6718] Loss: 0.0371\n",
      "Epoch [3] Iter [4600/6718] Loss: 0.1999\n",
      "Epoch [3] Iter [4700/6718] Loss: 0.2304\n",
      "Epoch [3] Iter [4800/6718] Loss: 0.0750\n",
      "Epoch [3] Iter [4900/6718] Loss: 0.3290\n",
      "Epoch [3] Iter [5000/6718] Loss: 0.1083\n",
      "Epoch [3] Iter [5100/6718] Loss: 0.0504\n",
      "Epoch [3] Iter [5200/6718] Loss: 0.1567\n",
      "Epoch [3] Iter [5300/6718] Loss: 0.2094\n",
      "Epoch [3] Iter [5400/6718] Loss: 0.4814\n",
      "Epoch [3] Iter [5500/6718] Loss: 0.2284\n",
      "Epoch [3] Iter [5600/6718] Loss: 0.2733\n",
      "Epoch [3] Iter [5700/6718] Loss: 0.3068\n",
      "Epoch [3] Iter [5800/6718] Loss: 0.2940\n",
      "Epoch [3] Iter [5900/6718] Loss: 0.1093\n",
      "Epoch [3] Iter [6000/6718] Loss: 0.2466\n",
      "Epoch [3] Iter [6100/6718] Loss: 0.1485\n",
      "Epoch [3] Iter [6200/6718] Loss: 0.1602\n",
      "Epoch [3] Iter [6300/6718] Loss: 0.2938\n",
      "Epoch [3] Iter [6400/6718] Loss: 0.0781\n",
      "Epoch [3] Iter [6500/6718] Loss: 0.0538\n",
      "Epoch [3] Iter [6600/6718] Loss: 0.5539\n",
      "Epoch [3] Iter [6700/6718] Loss: 0.1973\n",
      "Epoch [4] Iter [0/6718] Loss: 0.0502\n",
      "Epoch [4] Iter [100/6718] Loss: 0.1677\n",
      "Epoch [4] Iter [200/6718] Loss: 0.2155\n",
      "Epoch [4] Iter [300/6718] Loss: 0.3418\n",
      "Epoch [4] Iter [400/6718] Loss: 0.2118\n",
      "Epoch [4] Iter [500/6718] Loss: 0.0726\n",
      "Epoch [4] Iter [600/6718] Loss: 0.2518\n",
      "Epoch [4] Iter [700/6718] Loss: 0.4920\n",
      "Epoch [4] Iter [800/6718] Loss: 0.2155\n",
      "Epoch [4] Iter [900/6718] Loss: 0.2139\n",
      "Epoch [4] Iter [1000/6718] Loss: 0.3426\n",
      "Epoch [4] Iter [1100/6718] Loss: 0.0157\n",
      "Epoch [4] Iter [1200/6718] Loss: 0.2573\n",
      "Epoch [4] Iter [1300/6718] Loss: 0.1313\n",
      "Epoch [4] Iter [1400/6718] Loss: 0.3740\n",
      "Epoch [4] Iter [1500/6718] Loss: 0.1326\n",
      "Epoch [4] Iter [1600/6718] Loss: 0.3382\n",
      "Epoch [4] Iter [1700/6718] Loss: 0.0519\n",
      "Epoch [4] Iter [1800/6718] Loss: 0.1673\n",
      "Epoch [4] Iter [1900/6718] Loss: 0.2557\n",
      "Epoch [4] Iter [2000/6718] Loss: 0.1010\n",
      "Epoch [4] Iter [2100/6718] Loss: 0.0815\n",
      "Epoch [4] Iter [2200/6718] Loss: 0.7165\n",
      "Epoch [4] Iter [2300/6718] Loss: 0.3361\n",
      "Epoch [4] Iter [2400/6718] Loss: 0.0438\n",
      "Epoch [4] Iter [2500/6718] Loss: 0.0081\n",
      "Epoch [4] Iter [2600/6718] Loss: 0.2588\n",
      "Epoch [4] Iter [2700/6718] Loss: 0.1406\n",
      "Epoch [4] Iter [2800/6718] Loss: 0.1290\n",
      "Epoch [4] Iter [2900/6718] Loss: 0.2545\n",
      "Epoch [4] Iter [3000/6718] Loss: 0.5081\n",
      "Epoch [4] Iter [3100/6718] Loss: 0.1811\n",
      "Epoch [4] Iter [3200/6718] Loss: 0.4725\n",
      "Epoch [4] Iter [3300/6718] Loss: 0.3153\n",
      "Epoch [4] Iter [3400/6718] Loss: 0.1761\n",
      "Epoch [4] Iter [3500/6718] Loss: 0.3659\n",
      "Epoch [4] Iter [3600/6718] Loss: 0.2713\n",
      "Epoch [4] Iter [3700/6718] Loss: 0.1937\n",
      "Epoch [4] Iter [3800/6718] Loss: 0.2666\n",
      "Epoch [4] Iter [3900/6718] Loss: 0.0421\n",
      "Epoch [4] Iter [4000/6718] Loss: 0.1879\n",
      "Epoch [4] Iter [4100/6718] Loss: 0.1388\n",
      "Epoch [4] Iter [4200/6718] Loss: 0.2342\n",
      "Epoch [4] Iter [4300/6718] Loss: 0.1664\n",
      "Epoch [4] Iter [4400/6718] Loss: 0.3491\n",
      "Epoch [4] Iter [4500/6718] Loss: 0.3741\n",
      "Epoch [4] Iter [4600/6718] Loss: 0.0620\n",
      "Epoch [4] Iter [4700/6718] Loss: 0.6311\n",
      "Epoch [4] Iter [4800/6718] Loss: 0.2765\n",
      "Epoch [4] Iter [4900/6718] Loss: 0.2100\n",
      "Epoch [4] Iter [5000/6718] Loss: 0.1372\n",
      "Epoch [4] Iter [5100/6718] Loss: 0.1518\n",
      "Epoch [4] Iter [5200/6718] Loss: 0.2343\n",
      "Epoch [4] Iter [5300/6718] Loss: 0.3353\n",
      "Epoch [4] Iter [5400/6718] Loss: 0.2252\n",
      "Epoch [4] Iter [5500/6718] Loss: 0.3188\n",
      "Epoch [4] Iter [5600/6718] Loss: 0.4222\n",
      "Epoch [4] Iter [5700/6718] Loss: 0.6132\n",
      "Epoch [4] Iter [5800/6718] Loss: 0.2130\n",
      "Epoch [4] Iter [5900/6718] Loss: 0.1762\n",
      "Epoch [4] Iter [6000/6718] Loss: 0.4865\n",
      "Epoch [4] Iter [6100/6718] Loss: 0.2572\n",
      "Epoch [4] Iter [6200/6718] Loss: 0.1820\n",
      "Epoch [4] Iter [6300/6718] Loss: 0.2111\n",
      "Epoch [4] Iter [6400/6718] Loss: 0.0821\n",
      "Epoch [4] Iter [6500/6718] Loss: 0.1836\n",
      "Epoch [4] Iter [6600/6718] Loss: 0.2023\n",
      "Epoch [4] Iter [6700/6718] Loss: 0.1412\n"
     ]
    }
   ],
   "source": [
    "root = \"/kaggle/input/rdd-2022/RDD_SPLIT\"  \n",
    "num_classes = 6  \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "dataset = RDD2022Dataset(root, \"train\", transforms=get_transform(train=True))\n",
    "dataset_val = RDD2022Dataset(root, \"val\", transforms=get_transform(train=False))\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = get_model(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"road_damage_fasterrcnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6723075,
     "sourceId": 10827165,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19989.785216,
   "end_time": "2025-09-09T13:57:27.731791",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-09T08:24:17.946575",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
